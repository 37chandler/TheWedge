{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b5c2ca5",
   "metadata": {},
   "source": [
    "# Task 1: Building a Transaction Database in Google Big Query\n",
    "\n",
    "\n",
    "## In this task you’ll upload all Wedge transaction records to Google Big Query. You’ll want to make sure that the column data types are correctly specified and you’ve properly handled the null values. \n",
    "\n",
    "\n",
    "Note: this assignment can be done manually or programmatically. Naturally I’d prefer it be done programmatically so that you get more practice, but that’s not required to get full credit. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b06372f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages and libraries\n",
    "import os\n",
    "import re\n",
    "import io\n",
    "import datetime\n",
    "import sqlite3\n",
    "import csv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas_gbq\n",
    "import janitor\n",
    "import pprint\n",
    "\n",
    "import zipfile\n",
    "from zipfile import ZipFile\n",
    "\n",
    "# Google Big Query \n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e25433b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Paths for GBQ\n",
    "service_path = \"/Users/meganalbee/Desktop/ADA/key/\"\n",
    "service_file = 'albee-msba-4037d70faf07.json' # My Key   \n",
    "gbq_proj_id = 'albee-msba' # My GBQ \n",
    "dataset_id = 'wedge_msba' #Set to the Wedge\n",
    "\n",
    "#Private Key. Do not change. \n",
    "private_key = service_path + service_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53e492a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass in our credentials so that Python has permission to access our project\n",
    "credentials = service_account.Credentials.from_service_account_file(service_path + service_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99491414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish our connection\n",
    "client = bigquery.Client(credentials = credentials, project=gbq_proj_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08e4c4c",
   "metadata": {},
   "source": [
    "## Check dataset and proj in GBQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af8e1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in client.list_datasets() : \n",
    "    print(item.full_dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f56dc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = client.list_tables(dataset_id)  \n",
    "\n",
    "for table in tables:\n",
    "    if table :\n",
    "        print(table.table_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c23055",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_pattern = re.compile(r\"(\\D{12})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2662139f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will delete out the dataset for every table that matches\n",
    "for table in client.list_tables(dataset_id) :\n",
    "    if file_pattern.search(table.table_id) :\n",
    "        table_id = \".\".join([gbq_proj_id,dataset_id,table.table_id])\n",
    "        client.delete_table(table_id, not_found_ok=True)\n",
    "        \n",
    "        print(f\"Deleted {table.table_id}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99e2bd8",
   "metadata": {},
   "source": [
    "## Extract, Clean and Upload Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ad2b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting Headers. Based on Previous EDA. \n",
    "headers = ['\"datetime\"', '\"register_no\"', '\"emp_no\"', '\"trans_no\"', '\"upc\"', '\"description\"', '\"trans_type\"', '\"trans_subtype\"', '\"trans_status\"', '\"department\"', '\"quantity\"', '\"Scale\"', '\"cost\"', '\"unitPrice\"', '\"total\"', '\"regPrice\"', '\"altPrice\"', '\"tax\"', '\"taxexempt\"', '\"foodstamp\"', '\"wicable\"', '\"discount\"', '\"memDiscount\"', '\"discountable\"', '\"discounttype\"', '\"voided\"', '\"percentDiscount\"', '\"ItemQtty\"', '\"volDiscType\"', '\"volume\"', '\"VolSpecial\"', '\"mixMatch\"', '\"matched\"', '\"memType\"', '\"staff\"', '\"numflag\"', '\"itemstatus\"', '\"tenderstatus\"', '\"charflag\"', '\"varflag\"', '\"batchHeaderID\"', '\"local\"', '\"organic\"', '\"display\"', '\"receipt\"', '\"card_no\"', '\"store\"', '\"branch\"', '\"match_id\"', '\"trans_id\"']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b323814",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning through headers \n",
    "#This will be the header rows for files with no headers\n",
    "clean_headers = [i.replace('\"', '') for i in headers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1c9e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set os \n",
    "zip_files = os.listdir(\"WedgeZipOfZips/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93be0ab5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "delimiters = dict()\n",
    "obj_columns = []\n",
    "\n",
    "for this_zf in zip_files : \n",
    "    with ZipFile(\"WedgeZipOfZips/\" + this_zf, 'r') as zf :\n",
    "        zipped_files_name = zf.namelist()\n",
    "        \n",
    "        for file_name in zipped_files_name :\n",
    "            input_file = zf.open(file_name,'r')\n",
    "            input_file = io.TextIOWrapper(input_file,encoding=\"utf-8\")\n",
    "            \n",
    "            dialect = csv.Sniffer().sniff(sample=input_file.readline(),\n",
    "                                      delimiters=[\",\",\";\",\"\\t\"])\n",
    "            \n",
    "            delimiters[file_name] = dialect.delimiter\n",
    "            \n",
    "            #if header, read in file. If no header, set the header to clean_headers\n",
    "            for line in input_file :\n",
    "                if line[0] == \"datetime\" :\n",
    "                    df = pd.read_csv(input_file, sep = delimiters[file_name], encoding=\"utf-8\")                \n",
    "               \n",
    "                else :\n",
    "                    df = pd.read_csv(input_file, sep = delimiters[file_name], names = clean_headers, encoding=\"utf-8\")                 \n",
    "                \n",
    "            \n",
    "\n",
    "                df = janitor.clean_names(df)\n",
    "                df['datetime'] = pd.to_datetime(df.datetime, format='%Y-%m-%d %H:%M:%S')\n",
    "                df['department'] = df['department'].astype(\"str\")\n",
    "                df.department = df.department.fillna('')\n",
    "\n",
    "                #These columns throw errors in GBQ, created a list an enumerated\n",
    "                df[\"altprice\"] = df[\"altprice\"].astype(dtype = \"string\")\n",
    "                df[\"itemstatus\"] = df[\"itemstatus\"].astype(dtype = \"string\")\n",
    "                df[\"display\"] = df[\"display\"].astype(dtype = \"string\")\n",
    "                df[\"local\"] = df[\"local\"].astype(dtype = \"string\")\n",
    "                df[\"batchheaderid\"] = df[\"batchheaderid\"].astype(dtype = \"string\")\n",
    "                df[\"match_id\"] = df[\"match_id\"].astype(dtype = \"string\")\n",
    "                df[\"organic\"] = df[\"organic\"].astype(dtype = \"string\")\n",
    "                df[\"percentdiscount\"] = df[\"percentdiscount\"].astype(dtype = \"string\")\n",
    "                df[\"receipt\"] = df[\"receipt\"].astype(dtype = \"string\")\n",
    "                df[\"matched\"] = df[\"matched\"].astype(dtype = \"string\")\n",
    "                df[\"staff\"] = df[\"staff\"].astype(dtype = \"string\")\n",
    "                df[\"scale\"] = df[\"scale\"].astype(dtype = \"string\")\n",
    "                df[\"taxexempt\"] = df[\"taxexempt\"].astype(dtype = \"string\")\n",
    "                df[\"branch\"] = df[\"branch\"].astype(dtype = \"string\")\n",
    "                df[\"trans_id\"] = df[\"trans_id\"].astype(dtype = \"string\")\n",
    "                df[\"memtype\"] = df[\"memtype\"].astype(dtype = \"string\")\n",
    "                df[\"varflag\"] = df[\"varflag\"].astype(dtype = \"string\")\n",
    "                df[\"wicable\"] = df[\"wicable\"].astype(dtype = \"string\")\n",
    "                df[\"numflag\"] = df[\"numflag\"].astype(dtype = \"string\")\n",
    "                df[\"voided\"] = df[\"voided\"].astype(dtype = \"string\")\n",
    "                df[\"volume\"] = df[\"volume\"].astype(dtype = \"string\")\n",
    "                df[\"tax\"] = df[\"tax\"].astype(dtype = \"string\")\n",
    "                df[\"foodstamp\"] = df[\"foodstamp\"].astype(dtype = \"string\")\n",
    "                df[\"tenderstatus\"] = df[\"tenderstatus\"].astype(dtype = \"string\")\n",
    "\n",
    "                df['trans_status'] = df['trans_status'].astype(dtype = 'string')\n",
    "\n",
    "\n",
    "            \n",
    "                \n",
    " \n",
    "                for idx, column in enumerate(df) :\n",
    "                    if df[column].dtypes == \"object\" :        \n",
    "                        df = df.astype({column: 'str'})\n",
    "                    \n",
    "\n",
    "        \n",
    "               \n",
    "                table_name = file_name.replace('.csv','')\n",
    "                table_id = \".\".join([gbq_proj_id,dataset_id,table_name])\n",
    "                pandas_gbq.to_gbq(df, table_id, project_id=gbq_proj_id, if_exists=\"replace\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
